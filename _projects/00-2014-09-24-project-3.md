---
layout: project
title: TJBot-A Caring, Emotionally Intelligent Robot
date: Feb 2019
image: /public/images/tjbot.jpg
---

## Overview
My winter project for the Northwestern MSR program is to build/program a simple, caring emotionally intelligent robot using IBMâ€™s TJBot and Watson Services. The target audience is intended to be all people who want a companion, entertainment, or a support system during a difficult time. I will be custom naming the TJBot "David" in honor of my favorite filmmaker David Lynch. 

## Motivation
My Career goal is to improve the lives of people using Social Robotics. I believe this project is a good learning tool to investigate how Social Robotics research can benefit a broad audience and improve the well-being of people in versatile ways.  Currently there are challenges facing social robotics developers, such as having difficulty separating the technology from simple voice assistants. In addition, many chatbots and smart speakers that exist today have also shown to cause frustration in users, not only by erroneous responses, but also due to a lack of human emotion. Hence, I believe it is important to try to implement more natural and conversational language in the technology to humanize the experience, make users more comfortable, and develop more of a rapport with machines. While being inspired by chatbot therapists and companions that exist today, such as Replika and Woebot, I am motivated to pave the way for transforming this technology in the form of a Social Robot. I believe a cute robot that is physically always there, vs. on a phone screen, can make people feel even more at ease. 

## The final demo video shown below demonstrates a dialogue with the TJBot, who I named David (after my favorite filmmaker David Lynch). In this dialogue, the main goal was to utilize an initial tone of sadness from the user as input to the Watson services, which then begins a dialogue interaction between David and the user based on the sad tone. In addition, TJBot software capabilities were utilized which lights up a blue LED based on sadness. David receives, detect, and responds based on the initial tone of sadness. From there,a  natural, flowing dialogue for which David sounds concerned, and further asks the user the details of his sadness begins. I am simulating a scenario for which I have gone throuh a breakup. David then attempts to make me feel better and gets feedback from me on whether his response made me feel better. The resulting response from me indicates a positive emotion, and David lights his "sad blue" LED light from blue to "happy yellow" light and waves his arm three times as my happiness past a certain threshold of "happiness." The demo also demonstrates the use of humor, chosen in inspiration of utilizing multiple methods of improving human well being. See the test in action below. 

 [![IMAGE ALT TEXT](http://img.youtube.com/vi/qlEsNmaas20/0.jpg)](http://www.youtube.com/watch?v=qlEsNmaas20"Final Demo: David Makes a Sad User Feel Better")

 **IN WORK**: System flow diagrams and snapshots of the dialogue, shown in the form of "nodes". 

 Additional details on the project are outlined below. README updates INWORK. 

## Project Details
* **Summary of goals**: 
  * Run tests that demonstrate emotional, conversational, entertaining, and/or caring interactions between the robot and user based on various emotional moods from user (e.g. depressed, lonely, anxious, happy). Ideas include: TJBot conversing based on user input, telling jokes, dancing, sending media, analyzing tweets).  
 
  * **Hardware**: 
    * TJBot Kit
    *  Raspberry Pi 3
    *  USB Microphone
    *  Mini Bluetooth speaker
    *  Servo Motor
    *  NeoPixel RGB LED (8 mm)
    *  F-F plus F-M jumper wires
    *  Raspberry Pi Camera
  
  * **Software**:  
    * APIs from Watson Developer Cloud: IBM Watson Services as follows: 
      * Speech to Text (enables TJBot to listen to users speak and transcribe it to text)
      * Text to Speech (enables TJBot to speak)
      * Tone Analyzer (enables TJBot to detect emotions in text)
      * Watson Assistant (builds conversational interface with TJBot)
      * Visual Recognition (trains TJBot to recognize facial expressions) 
      * Node.js (to interface with these Watson Services)
      * Twitter API (to allow TJBot to detect emotions in tweets)

### Shown below is a video of a simple test demonstrating David's LED light shining as he detects sadness:

[link to video on YouTube.](https://www.youtube.com/watch?v=CHtvny04RFA)

[View the project on github here.](https://github.com/vnoelifant/tjbot-caring)

